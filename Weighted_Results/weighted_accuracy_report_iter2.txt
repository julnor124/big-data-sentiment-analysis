
WEIGHTED ACCURACY ANALYSIS REPORT - ITERATION 2
================================================

Generated: 2025-10-13 14:18:27

OVERVIEW
--------
This analysis adjusts accuracy metrics for class imbalance by weighting errors
based on the actual emotion distribution in the full dataset.

WHY WEIGHTED METRICS?
---------------------
- The evaluation sample has balanced emotions (equal numbers of each)
- The actual dataset is heavily imbalanced (much more neutral than disgust)
- Traditional accuracy gives equal weight to all emotions
- Weighted accuracy reflects real-world performance better

METHODOLOGY
-----------
For each emotion:
1. Calculate error rate from balanced sample
2. Get actual proportion in full dataset
3. Weight the error rate by actual proportion
4. Sum weighted errors across all emotions

Formula: Weighted Error Rate = Σ(error_rate_i × proportion_i)
where i = each emotion category


================================================================================
DATASET: Tweets AI Downsampled (Iter2)
================================================================================

Sample Evaluation:
- Sample size: 400 tweets (balanced)
- Incorrect labels: 188

Unweighted Metrics (traditional):
- Accuracy: 53.0%
- Error rate: 47.0%

Weighted Metrics (adjusted for class imbalance):
- Accuracy: 67.93%
- Error rate: 32.07%

Difference: 14.9 percentage points

Per-Emotion Analysis:

  ANGER:
    Error rate in sample: 31.6%
    Accuracy in sample: 68.4%
    Actual proportion in dataset: 1.3%
    Weighted contribution: 0.42% to total error

  DISGUST:
    Error rate in sample: 43.9%
    Accuracy in sample: 56.1%
    Actual proportion in dataset: 0.7%
    Weighted contribution: 0.32% to total error

  FEAR:
    Error rate in sample: 61.4%
    Accuracy in sample: 38.6%
    Actual proportion in dataset: 5.6%
    Weighted contribution: 3.42% to total error

  JOY:
    Error rate in sample: 28.1%
    Accuracy in sample: 71.9%
    Actual proportion in dataset: 5.0%
    Weighted contribution: 1.40% to total error

  NEUTRAL:
    Error rate in sample: 27.6%
    Accuracy in sample: 72.4%
    Actual proportion in dataset: 81.8%
    Weighted contribution: 22.56% to total error

  SADNESS:
    Error rate in sample: 64.9%
    Accuracy in sample: 35.1%
    Actual proportion in dataset: 0.9%
    Weighted contribution: 0.57% to total error

  SURPRISE:
    Error rate in sample: 71.9%
    Accuracy in sample: 28.1%
    Actual proportion in dataset: 4.7%
    Weighted contribution: 3.37% to total error

================================================================================
DATASET: Postlaunch (Iter2)
================================================================================

Sample Evaluation:
- Sample size: 400 tweets (balanced)
- Incorrect labels: 138

Unweighted Metrics (traditional):
- Accuracy: 65.5%
- Error rate: 34.5%

Weighted Metrics (adjusted for class imbalance):
- Accuracy: 78.84%
- Error rate: 21.16%

Difference: 13.3 percentage points

Per-Emotion Analysis:

  ANGER:
    Error rate in sample: 22.8%
    Accuracy in sample: 77.2%
    Actual proportion in dataset: 3.2%
    Weighted contribution: 0.72% to total error

  DISGUST:
    Error rate in sample: 31.6%
    Accuracy in sample: 68.4%
    Actual proportion in dataset: 1.5%
    Weighted contribution: 0.47% to total error

  FEAR:
    Error rate in sample: 66.7%
    Accuracy in sample: 33.3%
    Actual proportion in dataset: 7.2%
    Weighted contribution: 4.78% to total error

  JOY:
    Error rate in sample: 21.1%
    Accuracy in sample: 78.9%
    Actual proportion in dataset: 9.9%
    Weighted contribution: 2.09% to total error

  NEUTRAL:
    Error rate in sample: 13.8%
    Accuracy in sample: 86.2%
    Actual proportion in dataset: 65.6%
    Weighted contribution: 9.05% to total error

  SADNESS:
    Error rate in sample: 63.2%
    Accuracy in sample: 36.8%
    Actual proportion in dataset: 2.9%
    Weighted contribution: 1.82% to total error

  SURPRISE:
    Error rate in sample: 22.8%
    Accuracy in sample: 77.2%
    Actual proportion in dataset: 9.8%
    Weighted contribution: 2.23% to total error


OVERALL FINDINGS - ITERATION 2
-------------------------------

Tweets AI Downsampled (Iter2):
  - Unweighted accuracy: 53.0%
  - Weighted accuracy: 67.93%
  - Model performs better than unweighted metrics suggest (14.9pp difference)

Postlaunch (Iter2):
  - Unweighted accuracy: 65.5%
  - Weighted accuracy: 78.84%
  - Model performs better than unweighted metrics suggest (13.3pp difference)


INTERPRETATION
--------------

The weighted metrics provide a more realistic view of model performance because:

1. REFLECTS REAL USAGE: Weights errors by how often each emotion appears
2. PRIORITIZES COMMON EMOTIONS: Better performance on frequent emotions (neutral)
   matters more than rare ones (disgust)
3. PRODUCTION ACCURACY: Shows expected performance on real data distribution

RECOMMENDATIONS
---------------

1. If weighted accuracy > unweighted:
   ✓ Model is good at common emotions
   ✓ Acceptable for production use
   ✗ May struggle with rare emotions - monitor these

2. If weighted accuracy < unweighted:
   ✗ Model struggles with common emotions
   ⚠ Consider improving model for frequent categories
   ✓ Good at rare emotions (but less impactful)

3. For balanced performance:
   - Use class weights during training
   - Oversample rare emotions
   - Use stratified sampling for evaluation
